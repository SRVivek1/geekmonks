<h1>LLM Engineering - Architectures, Prompting, and Reasoning</h1>

<p>
  Updated on: 31 Oct 2025
  
  
  
    - <a href="/geekmonks/authors/srvivek/">Vivek Singh</a>
  
</p>

<hr/>

<blockquote>
  <ul>
    <li>This section covers the core ‘breeds’ of Large Language Models (LLMs), a key advanced prompting technique, and emerging methods for controlling model reasoning and budgeting.</li>
    <li>The target audience is intermediate developers and researchers seeking to deepen their understanding of how modern LLMs are structured and controlled.</li>
  </ul>
</blockquote>

<h2 id="table-of-contents">Table of Contents</h2>
<ul>
  <li><a href="#table-of-contents">Table of Contents</a></li>
  <li><a href="#core-llm-architectures-and-breeds">Core LLM Architectures and Breeds</a>
    <ul>
      <li><a href="#1-base-models">1. Base Models</a></li>
      <li><a href="#2-chatinstruct-models">2. Chat/Instruct Models</a></li>
      <li><a href="#3-reasoningthinking-models">3. Reasoning/Thinking Models</a></li>
      <li><a href="#4-hybrid-models">4. Hybrid Models</a></li>
    </ul>
  </li>
  <li><a href="#advanced-prompt-engineering-chain-of-thought-cot">Advanced Prompt Engineering: Chain-of-Thought (CoT)</a>
    <ul>
      <li><a href="#the-chain-of-thought-mechanism">The Chain-of-Thought Mechanism</a></li>
    </ul>
  </li>
  <li><a href="#controlling-llm-reasoning-and-budget">Controlling LLM Reasoning and Budget</a>
    <ul>
      <li><a href="#reasoning-models-in-practice">Reasoning Models in Practice</a></li>
      <li><a href="#1-budget-forcing">1. Budget Forcing</a></li>
      <li><a href="#2-reinforcing-reasoning-with-weighted-keywords">2. Reinforcing Reasoning with Weighted Keywords</a></li>
    </ul>
  </li>
  <li><a href="#key-takeaways">Key Takeaways</a></li>
</ul>

<hr />

<h2 id="core-llm-architectures-and-breeds">Core LLM Architectures and Breeds</h2>

<p>Modern Large Language Models (LLMs) are typically categorized into <strong>three main ‘breeds’</strong>, reflecting their primary training objective and intended use case. This distinction is crucial for selecting the right model for a specific engineering task, whether it’s raw text completion or complex problem-solving.</p>

<h3 id="1-base-models">1. Base Models</h3>

<ul>
  <li><strong>Definition:</strong> The initial state of a large language model after the foundational <strong>pre-training</strong> phase on massive datasets (e.g., Common Crawl, Wikipedia).</li>
  <li><strong>Function:</strong> Its sole purpose is <strong>autoregressive prediction</strong>—taking a sequence of information (input) and predicting the most probable next token (output). It is trained only for next-token prediction, lacking explicit alignment for human instructions or safety.</li>
  <li><strong>Use Case:</strong> Base models are rarely used directly in production but are the preferred starting point when the goal is to <strong>fine-tune</strong> the model to acquire an entirely new skill or adapt it to a highly specialized, domain-specific task.</li>
  <li><strong>Alignment Step:</strong> To move from a raw base model (like the original GPT) to a model that follows instructions (like ChatGPT), a process called <strong>Reinforcement Learning from Human Feedback (RLHF)</strong> is often applied. This step aligns the model’s output with human preferences.</li>
</ul>

<h3 id="2-chatinstruct-models">2. Chat/Instruct Models</h3>

<ul>
  <li><strong>Definition:</strong> These models are fine-tuned versions of a Base Model, primarily through <strong>Supervised Fine-Tuning (SFT)</strong> and often <strong>RLHF</strong>.</li>
  <li><strong>Function:</strong> They are explicitly trained to follow instructions and engage in dialogue. They excel at interactive use cases, content generation, summarization, and translation.</li>
  <li><strong>Key Advantage:</strong> They are generally better at generating <strong>cohesive, conversational responses</strong> and adhering to format constraints provided in a prompt.</li>
</ul>

<h3 id="3-reasoningthinking-models">3. Reasoning/Thinking Models</h3>

<ul>
  <li><strong>Definition:</strong> A class of models or a specific mode within a model architecture optimized for complex, multi-step problem-solving.</li>
  <li><strong>Function:</strong> These models are designed to use an <strong>internal, structured process</strong> to break down a problem, often referred to as a ‘thinking’ or ‘scratchpad’ phase, before providing the final answer.</li>
  <li><strong>Key Advantage:</strong> They are more effective in tasks requiring <strong>logical deduction</strong>, mathematical problem-solving, and managing complex constraints.</li>
</ul>

<h3 id="4-hybrid-models">4. Hybrid Models</h3>

<ul>
  <li><strong>Definition:</strong> The latest generation of cutting-edge LLMs that combine the strengths of both Chat/Instruct and Reasoning/Thinking models.</li>
  <li><strong>Examples:</strong> Models like <strong>Gemini Pro 2.5</strong> and <strong>GPT-5</strong> are examples of this new breed.</li>
  <li><strong>Function:</strong> They offer <strong>state-of-the-art performance</strong> across a wide spectrum of tasks, capable of both nuanced conversational output and deep, multi-step reasoning.</li>
  <li><strong>Practical Note:</strong> Open-source projects often release both a pure chat-optimized version and a more robust hybrid version, allowing engineers to select based on specific resource and task needs.</li>
</ul>

<hr />

<h2 id="advanced-prompt-engineering-chain-of-thought-cot">Advanced Prompt Engineering: Chain-of-Thought (CoT)</h2>

<p><strong>Prompt engineering</strong> is the art of crafting inputs to elicit desired, high-quality outputs from an LLM. <strong>Chain-of-Thought (CoT)</strong> prompting is a highly effective, yet simple, technique to significantly improve a model’s performance on reasoning-intensive tasks.</p>

<h3 id="the-chain-of-thought-mechanism">The Chain-of-Thought Mechanism</h3>

<ul>
  <li>1. <strong>Core Idea:</strong> By prompting the model to explicitly show its work, you allow it to allocate more internal computational resources to the problem-solving process. This often involves generating an intermediate, <em>private</em> reasoning trace.</li>
  <li>2. <strong>The Simple CoT Trick:</strong> The most basic and effective application involves appending a simple phrase to your prompt:
    <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  "Please think step by step."
</code></pre></div>    </div>
    <p>or</p>
    <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  "Let's break this down before giving the final answer."
</code></pre></div>    </div>
  </li>
  <li><strong>Result:</strong> When instructed to use CoT, the model goes through the problem methodically, increasing the likelihood that the predicted sequence of tokens (the final answer) is logically sound and correct.</li>
</ul>

<hr />

<h2 id="controlling-llm-reasoning-and-budget">Controlling LLM Reasoning and Budget</h2>

<p>As LLMs become more complex, techniques for managing their internal reasoning processes and the computational <strong>budget</strong> allocated to a query are becoming essential for efficiency and performance.</p>

<h3 id="reasoning-models-in-practice">Reasoning Models in Practice</h3>

<p>When working with models optimized for reasoning, understanding that they operate with an <em>internal</em> thought process is key. The <strong>goal of advanced control techniques</strong> is to influence this internal process.</p>

<h3 id="1-budget-forcing">1. Budget Forcing</h3>

<ul>
  <li><strong>Concept:</strong> This technique involves controlling the <strong>computational resources</strong> (the ‘budget’) an LLM uses to generate an intermediate reasoning trace. In many advanced architectures, the model might first generate a thought (using a specified number of tokens/compute) before committing to a final answer.</li>
  <li><strong>Application:</strong> By forcing a minimum or maximum <strong>reasoning budget</strong>, engineers can fine-tune the trade-off between <strong>latency (speed)</strong> and <strong>accuracy (quality)</strong>. A higher budget may improve complex reasoning accuracy but will increase inference time.</li>
</ul>

<h3 id="2-reinforcing-reasoning-with-weighted-keywords">2. Reinforcing Reasoning with Weighted Keywords</h3>

<ul>
  <li><strong>The Discovery (Reported Jan 2025):</strong> Emerging research suggests that it’s possible to selectively reinforce the model’s internal thinking process by strategically introducing <strong>weighted keywords</strong> into the prompt or, more accurately, into the model’s internal processing layers.</li>
  <li><strong>Mechanism (Conceptual):</strong> The concept is to use a specific keyword (or set of keywords) that, when processed, causes a temporary <strong>up-weighting</strong> of attention or activation in the layers responsible for reasoning. This can:
    <ul>
      <li><strong>Reinforce reasoning:</strong> Encourage the model to spend more internal cycles on logical checking.</li>
      <li><strong>Focus the reasoning:</strong> Direct the model’s internal thought process toward specific concepts or constraints critical to the problem.</li>
    </ul>
  </li>
</ul>

<p>This is a subtle, advanced technique that goes beyond surface-level prompt engineering, touching on the control mechanisms of the underlying LLM architecture.</p>

<hr />

<h2 id="key-takeaways">Key Takeaways</h2>

<ul>
  <li><strong>Model Selection is Crucial:</strong> The choice between a <strong>Base Model</strong> (for new skills), a <strong>Chat/Instruct Model</strong> (for conversation), or a <strong>Hybrid Model</strong> (for SOTA performance) directly impacts project feasibility and outcome.</li>
  <li><strong>CoT is Low-Cost, High-Reward:</strong> Simple phrases like <code class="language-plaintext highlighter-rouge">"Please think step by step."</code> are a powerful, almost zero-cost method for boosting the reasoning capabilities of most modern LLMs.</li>
  <li><strong>Control the Process, Not Just the Output:</strong> Advanced LLM engineering is moving toward managing the model’s internal state via techniques like <strong>Budget Forcing</strong> and <strong>Weighted Keyword Reinforcement</strong> to optimize for both performance and efficiency.</li>
</ul>

<!-- Adding a gray border in bottom of page. -->
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code></code></pre></div></div>


<!-- TODO: add footer -->