<!DOCTYPE html>
<html lang="en">

<!-- HTML Head-->
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css" rel="stylesheet">
    <link href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.10.5/font/bootstrap-icons.css" rel="stylesheet">
    <link rel="stylesheet" href="/geekmonks/assets/css/styles.css">
    <link type="application/atom+xml" rel="alternate" href="https://srvivek1.github.io/geekmonks/feed.xml" title="Geekmonks Blog" />
    <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Introduction to LLMs | Geekmonks Blog</title>
<meta name="generator" content="Jekyll v3.10.0" />
<meta property="og:title" content="Introduction to LLMs" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="This section covers the core ‘breeds’ of Large Language Models (LLMs), a key advanced prompting technique, and emerging methods for controlling model reasoning and budgeting. The target audience is intermediate developers and researchers seeking to deepen their understanding of how modern LLMs are structured and controlled." />
<meta property="og:description" content="This section covers the core ‘breeds’ of Large Language Models (LLMs), a key advanced prompting technique, and emerging methods for controlling model reasoning and budgeting. The target audience is intermediate developers and researchers seeking to deepen their understanding of how modern LLMs are structured and controlled." />
<link rel="canonical" href="https://srvivek1.github.io/geekmonks/ai-ml/llm-engineering/introduction-to-llms.html" />
<meta property="og:url" content="https://srvivek1.github.io/geekmonks/ai-ml/llm-engineering/introduction-to-llms.html" />
<meta property="og:site_name" content="Geekmonks Blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-10-25T00:00:00+05:30" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Introduction to LLMs" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2025-10-25T00:00:00+05:30","datePublished":"2025-10-25T00:00:00+05:30","description":"This section covers the core ‘breeds’ of Large Language Models (LLMs), a key advanced prompting technique, and emerging methods for controlling model reasoning and budgeting. The target audience is intermediate developers and researchers seeking to deepen their understanding of how modern LLMs are structured and controlled.","headline":"Introduction to LLMs","mainEntityOfPage":{"@type":"WebPage","@id":"https://srvivek1.github.io/geekmonks/ai-ml/llm-engineering/introduction-to-llms.html"},"url":"https://srvivek1.github.io/geekmonks/ai-ml/llm-engineering/introduction-to-llms.html"}</script>
<!-- End Jekyll SEO tag -->

    <!-- Google Analytics -->
    <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-48XEHMVSEC"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-48XEHMVSEC');
</script>
</head>

<body class="container-fluid p-0 m-0">
    <header>
        <nav class="navbar navbar-expand-md navbar-light bg-light text-white content-shadow">
  <div class="container d-flex justify-content-between">
    <a href="/geekmonks/" class="navbar-brand d-flex">
      <img class="d-inline-block align-top" src="/geekmonks/assets/icons/laptop.svg" height="40"
        width="34" />
      <h1 class="fs-3 px-2 fw-bold">Geekmonks</h1>
      <img class="d-inline-block align-top" src="/geekmonks/assets/icons/tux.svg" height="40"
        width="34" />
    </a>
    <!-- Toggle Button to expand and collapse the nav links -->
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNavBanner"
      aria-controls="navbarNavBanner" aria-expanded="false" aria-label="Toggle Navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbarNavBanner" class="collapse navbar-collapse">
      <ul class="navbar-nav ms-auto">
        
        <li class="nav-item active">
          <a href="/geekmonks/" class="nav-link fw-bold active"
            >Home</a>
        </li>
        
        <li class="nav-item active">
          <a href="/geekmonks/blog" class="nav-link fw-bold active"
            >Blog</a>
        </li>
        
        <li class="nav-item active">
          <a href="/geekmonks/about" class="nav-link fw-bold active"
            >About</a>
        </li>
        
        <li class="nav-item active">
          <a href="/geekmonks/staff" class="nav-link fw-bold active"
            >Staff</a>
        </li>
        
        <li class="nav-item active">
          <a href="https://github.com/SRVivek1/" class="nav-link fw-bold active"
            target="_blank" rel="noopener noreferrer">Github</a>
        </li>
        
        <li class="nav-item active">
          <a href="https://www.linkedin.com/in/srvivek1/" class="nav-link fw-bold active"
            target="_blank" rel="noopener noreferrer">LinkedIn</a>
        </li>
        
      </ul>
    </div>
  </div>
</nav>
        <nav class="navbar navbar-expand-xl navbar-custom p-0">
  <div class="container-fluid">

    <!-- Toggler for small screens -->
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <!-- Collapsible nav items -->
    <div class="collapse navbar-collapse" id="navbarNav">
      <ul class="navbar-nav mx-auto">
        
          
          
            
              <!-- Simple nav item -->
              <li class="nav-item">
                <a class="nav-link fw-bold text-white" href="/geekmonks/ai-ml/llm-engineering/"
                  >AI-ML</a>
              </li>
            
          
            
              <!-- Simple nav item -->
              <li class="nav-item">
                <a class="nav-link fw-bold text-white" href="/geekmonks/cloud/aws/"
                  >AWS</a>
              </li>
            
          
            
              <!-- Simple nav item -->
              <li class="nav-item">
                <a class="nav-link fw-bold text-white" href="/geekmonks/spring/spring-boot/"
                  >Spring Boot</a>
              </li>
            
          
        
      </ul>
    </div>
  </div>
</nav>
    </header>

    <div class="container-fluid">
        <div class="row min-vh-100">
            <!-- Left Sidebar -->
            <nav id="course-sidebar" class="col-md-3 col-lg-2 d-md-block bg-light sidebar collapse">
                <div class="position-sticky pt-3">
                    <ul class="nav flex-column course-topics-list">
                        
                        
                        
                        
                        
                        
                        <a class="nav-link course-link active"
                            href="/geekmonks/ai-ml/llm-engineering" data-course="ai-ml/llm-engineering">
                            AI/ML
                        </a>
                        <!-- Debug - Submenu links are broken -->
                        
                        <ul class="nav flex-column ms-3 subtopics" id="topics-ai-ml-llm-engineering">
                            
                            <li class="nav-item">
                                <a class="nav-link topic-link small" href="introduction-to-llms.html"
                                    data-topic="introduction-to-llms.html"
                                    data-course-path="/ai-ml/llm-engineering">
                                    LLM Fundamentals
                                </a>
                            </li>
                            
                            <li class="nav-item">
                                <a class="nav-link topic-link small" href="frontier-models-capabilities-operational-risks.html"
                                    data-topic="frontier-models-capabilities-operational-risks.html"
                                    data-course-path="/ai-ml/llm-engineering">
                                    Architecture & capabilities
                                </a>
                            </li>
                            
                            <li class="nav-item">
                                <a class="nav-link topic-link small" href="foundaion-and-evolution.html"
                                    data-topic="foundaion-and-evolution.html"
                                    data-course-path="/ai-ml/llm-engineering">
                                    Foundation and Evaluation
                                </a>
                            </li>
                            
                            <li class="nav-item">
                                <a class="nav-link topic-link small" href="advance-concepts-toknization-and-scaling.html"
                                    data-topic="advance-concepts-toknization-and-scaling.html"
                                    data-course-path="/ai-ml/llm-engineering">
                                    Advanced - Tokens, Scaling
                                </a>
                            </li>
                            
                            <li class="nav-item">
                                <a class="nav-link topic-link small" href="scaling-reasoning-inference.html"
                                    data-topic="scaling-reasoning-inference.html"
                                    data-course-path="/ai-ml/llm-engineering">
                                    Advanced - Reasoning, Interference
                                </a>
                            </li>
                            
                            <li class="nav-item">
                                <a class="nav-link topic-link small" href="payload-tokenization.html"
                                    data-topic="payload-tokenization.html"
                                    data-course-path="/ai-ml/llm-engineering">
                                    Advanced - Payload Tokenization
                                </a>
                            </li>
                            
                            <li class="nav-item">
                                <a class="nav-link topic-link small" href="advance-conectps-models-deployments.html"
                                    data-topic="advance-conectps-models-deployments.html"
                                    data-course-path="/ai-ml/llm-engineering">
                                    Advanced Concepts & Deployment
                                </a>
                            </li>
                            
                            <li class="nav-item">
                                <a class="nav-link topic-link small" href="advance-prompt-caching.html"
                                    data-topic="advance-prompt-caching.html"
                                    data-course-path="/ai-ml/llm-engineering">
                                    Advanced - Prompt Caching
                                </a>
                            </li>
                            
                        </ul>
                        
                        
                        
                        
                    </ul>
                </div>
            </nav>

            <!-- Right Content Panel -->
            <main class="col-md-9 ms-sm-auto col-lg-10 px-md-4">
                <!-- Mobile: toggle sidebar button -->
                <button id="sidebarToggle" class="btn btn-sm btn-outline-secondary d-md-none mb-2"
                    aria-label="Toggle topics" aria-controls="course-sidebar">
                    ☰ Topics
                </button>



                <div id="topic-content">
                    <div id="pageTitle">
                        <h1>Introduction to LLMs </h1>
                        <p>
                            Updated on: 25 Oct 2025

                            
                            
                            - <a href="/geekmonks/authors/srvivek/">Vivek Singh</a>
                            
                        </p>

                        <hr class="stylish-hr"/>
                    </div>

                    <blockquote>
  <ul>
    <li>This section covers the core ‘breeds’ of Large Language Models (LLMs), a key advanced prompting technique, and emerging methods for controlling model reasoning and budgeting.</li>
    <li>The target audience is intermediate developers and researchers seeking to deepen their understanding of how modern LLMs are structured and controlled.</li>
  </ul>
</blockquote>

<h2 id="table-of-contents">Table of Contents</h2>
<ul>
  <li><a href="#table-of-contents">Table of Contents</a></li>
  <li><a href="#core-llm-architectures-and-breeds">Core LLM Architectures and Breeds</a>
    <ul>
      <li><a href="#1-base-models">1. Base Models</a></li>
      <li><a href="#2-chatinstruct-models">2. Chat/Instruct Models</a></li>
      <li><a href="#3-reasoningthinking-models">3. Reasoning/Thinking Models</a></li>
      <li><a href="#4-hybrid-models">4. Hybrid Models</a></li>
    </ul>
  </li>
  <li><a href="#advanced-prompt-engineering-chain-of-thought-cot">Advanced Prompt Engineering: Chain-of-Thought (CoT)</a>
    <ul>
      <li><a href="#the-chain-of-thought-mechanism">The Chain-of-Thought Mechanism</a></li>
    </ul>
  </li>
  <li><a href="#controlling-llm-reasoning-and-budget">Controlling LLM Reasoning and Budget</a>
    <ul>
      <li><a href="#reasoning-models-in-practice">Reasoning Models in Practice</a></li>
      <li><a href="#1-budget-forcing">1. Budget Forcing</a></li>
      <li><a href="#2-reinforcing-reasoning-with-weighted-keywords">2. Reinforcing Reasoning with Weighted Keywords</a></li>
    </ul>
  </li>
  <li><a href="#key-takeaways">Key Takeaways</a></li>
</ul>

<hr />

<h2 id="core-llm-architectures-and-breeds">Core LLM Architectures and Breeds</h2>

<p>Modern Large Language Models (LLMs) are typically categorized into <strong>three main ‘breeds’</strong>, reflecting their primary training objective and intended use case. This distinction is crucial for selecting the right model for a specific engineering task, whether it’s raw text completion or complex problem-solving.</p>

<h3 id="1-base-models">1. Base Models</h3>

<ul>
  <li><strong>Definition:</strong> The initial state of a large language model after the foundational <strong>pre-training</strong> phase on massive datasets (e.g., Common Crawl, Wikipedia).</li>
  <li><strong>Function:</strong> Its sole purpose is <strong>autoregressive prediction</strong>—taking a sequence of information (input) and predicting the most probable next token (output). It is trained only for next-token prediction, lacking explicit alignment for human instructions or safety.</li>
  <li><strong>Use Case:</strong> Base models are rarely used directly in production but are the preferred starting point when the goal is to <strong>fine-tune</strong> the model to acquire an entirely new skill or adapt it to a highly specialized, domain-specific task.</li>
  <li><strong>Alignment Step:</strong> To move from a raw base model (like the original GPT) to a model that follows instructions (like ChatGPT), a process called <strong>Reinforcement Learning from Human Feedback (RLHF)</strong> is often applied. This step aligns the model’s output with human preferences.</li>
</ul>

<h3 id="2-chatinstruct-models">2. Chat/Instruct Models</h3>

<ul>
  <li><strong>Definition:</strong> These models are fine-tuned versions of a Base Model, primarily through <strong>Supervised Fine-Tuning (SFT)</strong> and often <strong>RLHF</strong>.</li>
  <li><strong>Function:</strong> They are explicitly trained to follow instructions and engage in dialogue. They excel at interactive use cases, content generation, summarization, and translation.</li>
  <li><strong>Key Advantage:</strong> They are generally better at generating <strong>cohesive, conversational responses</strong> and adhering to format constraints provided in a prompt.</li>
</ul>

<h3 id="3-reasoningthinking-models">3. Reasoning/Thinking Models</h3>

<ul>
  <li><strong>Definition:</strong> A class of models or a specific mode within a model architecture optimized for complex, multi-step problem-solving.</li>
  <li><strong>Function:</strong> These models are designed to use an <strong>internal, structured process</strong> to break down a problem, often referred to as a ‘thinking’ or ‘scratchpad’ phase, before providing the final answer.</li>
  <li><strong>Key Advantage:</strong> They are more effective in tasks requiring <strong>logical deduction</strong>, mathematical problem-solving, and managing complex constraints.</li>
</ul>

<h3 id="4-hybrid-models">4. Hybrid Models</h3>

<ul>
  <li><strong>Definition:</strong> The latest generation of cutting-edge LLMs that combine the strengths of both Chat/Instruct and Reasoning/Thinking models.</li>
  <li><strong>Examples:</strong> Models like <strong>Gemini Pro 2.5</strong> and <strong>GPT-5</strong> are examples of this new breed.</li>
  <li><strong>Function:</strong> They offer <strong>state-of-the-art performance</strong> across a wide spectrum of tasks, capable of both nuanced conversational output and deep, multi-step reasoning.</li>
  <li><strong>Practical Note:</strong> Open-source projects often release both a pure chat-optimized version and a more robust hybrid version, allowing engineers to select based on specific resource and task needs.</li>
</ul>

<hr />

<h2 id="advanced-prompt-engineering-chain-of-thought-cot">Advanced Prompt Engineering: Chain-of-Thought (CoT)</h2>

<p><strong>Prompt engineering</strong> is the art of crafting inputs to elicit desired, high-quality outputs from an LLM. <strong>Chain-of-Thought (CoT)</strong> prompting is a highly effective, yet simple, technique to significantly improve a model’s performance on reasoning-intensive tasks.</p>

<h3 id="the-chain-of-thought-mechanism">The Chain-of-Thought Mechanism</h3>

<ul>
  <li>1. <strong>Core Idea:</strong> By prompting the model to explicitly show its work, you allow it to allocate more internal computational resources to the problem-solving process. This often involves generating an intermediate, <em>private</em> reasoning trace.</li>
  <li>2. <strong>The Simple CoT Trick:</strong> The most basic and effective application involves appending a simple phrase to your prompt:
    <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  "Please think step by step."
</code></pre></div>    </div>
    <p>or</p>
    <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  "Let's break this down before giving the final answer."
</code></pre></div>    </div>
  </li>
  <li><strong>Result:</strong> When instructed to use CoT, the model goes through the problem methodically, increasing the likelihood that the predicted sequence of tokens (the final answer) is logically sound and correct.</li>
</ul>

<hr />

<h2 id="controlling-llm-reasoning-and-budget">Controlling LLM Reasoning and Budget</h2>

<p>As LLMs become more complex, techniques for managing their internal reasoning processes and the computational <strong>budget</strong> allocated to a query are becoming essential for efficiency and performance.</p>

<h3 id="reasoning-models-in-practice">Reasoning Models in Practice</h3>

<p>When working with models optimized for reasoning, understanding that they operate with an <em>internal</em> thought process is key. The <strong>goal of advanced control techniques</strong> is to influence this internal process.</p>

<h3 id="1-budget-forcing">1. Budget Forcing</h3>

<ul>
  <li><strong>Concept:</strong> This technique involves controlling the <strong>computational resources</strong> (the ‘budget’) an LLM uses to generate an intermediate reasoning trace. In many advanced architectures, the model might first generate a thought (using a specified number of tokens/compute) before committing to a final answer.</li>
  <li><strong>Application:</strong> By forcing a minimum or maximum <strong>reasoning budget</strong>, engineers can fine-tune the trade-off between <strong>latency (speed)</strong> and <strong>accuracy (quality)</strong>. A higher budget may improve complex reasoning accuracy but will increase inference time.</li>
</ul>

<h3 id="2-reinforcing-reasoning-with-weighted-keywords">2. Reinforcing Reasoning with Weighted Keywords</h3>

<ul>
  <li><strong>The Discovery (Reported Jan 2025):</strong> Emerging research suggests that it’s possible to selectively reinforce the model’s internal thinking process by strategically introducing <strong>weighted keywords</strong> into the prompt or, more accurately, into the model’s internal processing layers.</li>
  <li><strong>Mechanism (Conceptual):</strong> The concept is to use a specific keyword (or set of keywords) that, when processed, causes a temporary <strong>up-weighting</strong> of attention or activation in the layers responsible for reasoning. This can:
    <ul>
      <li><strong>Reinforce reasoning:</strong> Encourage the model to spend more internal cycles on logical checking.</li>
      <li><strong>Focus the reasoning:</strong> Direct the model’s internal thought process toward specific concepts or constraints critical to the problem.</li>
    </ul>
  </li>
</ul>

<p>This is a subtle, advanced technique that goes beyond surface-level prompt engineering, touching on the control mechanisms of the underlying LLM architecture.</p>

<hr />

<h2 id="key-takeaways">Key Takeaways</h2>

<ul>
  <li><strong>Model Selection is Crucial:</strong> The choice between a <strong>Base Model</strong> (for new skills), a <strong>Chat/Instruct Model</strong> (for conversation), or a <strong>Hybrid Model</strong> (for SOTA performance) directly impacts project feasibility and outcome.</li>
  <li><strong>CoT is Low-Cost, High-Reward:</strong> Simple phrases like <code class="language-plaintext highlighter-rouge">"Please think step by step."</code> are a powerful, almost zero-cost method for boosting the reasoning capabilities of most modern LLMs.</li>
  <li><strong>Control the Process, Not Just the Output:</strong> Advanced LLM engineering is moving toward managing the model’s internal state via techniques like <strong>Budget Forcing</strong> and <strong>Weighted Keyword Reinforcement</strong> to optimize for both performance and efficiency.</li>
</ul>

<!-- Adding a gray border in bottom of page. -->
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code></code></pre></div></div>
 <!-- Injects index.md content here -->
                </div>
            </main>
        </div>
    </div>

    <!-- External scripts -->
    <!-- bootstrap -->
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/js/bootstrap.bundle.min.js" defer></script>

<!-- Mermaid JS: render diagrams client-side. We convert fenced code blocks
		 with class `language-mermaid` into <div class="mermaid"> so existing
		 markdown files don't need editing. -->
<script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
<!-- Include internal JavaScript -->
 <script src="/geekmonks/assets/js/mermaid-diagram-render.js"></script>


 <!-- Submenu toggle nav on small screen-->
<script src="/geekmonks/assets/js/submenu-togle.js"></script>


</body>

</html>